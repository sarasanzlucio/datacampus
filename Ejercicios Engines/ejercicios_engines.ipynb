{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edee7cd",
   "metadata": {},
   "source": [
    "# DATA CAMPUS BBVA\n",
    "# ANALYTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882d91c",
   "metadata": {},
   "source": [
    "## EJERCICIOS DE ENGINES\n",
    "\n",
    "### 1. Combinación de dataframes\n",
    "##### 1. Escribe un programa que, empleando la librería Pandas, lea en dataframes los csv data1 y data2 y combine ambos dataframes utilizando como clave la columna key1 y guarde el dataframe resultante en un fichero csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv data1\n",
    "# Read csv data2\n",
    "\n",
    "# Merge csv\n",
    "\n",
    "# Write resulting dataframe to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a279423",
   "metadata": {},
   "source": [
    "### 2. Filtros\n",
    "\n",
    "##### 2. Escribe un programa que lea en un dataframe el contenido del dataset \"consumicion_alcohol_mundial.csv\" y realice lo siguiente:\n",
    "- Encontrar y eliminar los Missing Values del dataframe\n",
    "- Eliminar aquellas filas en las que el valor de la columna 'WHO Region\" esté duplicado\n",
    "- Seleccionar la información del dataset sobre la consumición de alcohol en 'Americas' en el año 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d41173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv consumicion_alcohol_mundial\n",
    "\n",
    "# Find missing values and drop them\n",
    "\n",
    "# Drop duplicates\n",
    "\n",
    "# Filter region Americas and year 1989\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa62ef6",
   "metadata": {},
   "source": [
    "### 3. Grupos y funciones agregadas\n",
    "\n",
    "##### 3.1 Realiza un programa que agrupe los datos del dataframe descrito a continuación por el campo 'salesman_id' y obtenga la primera fecha de ord_date para cada uno de estos grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b528065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given the following dataframe\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5004,5003,5002,5004,5001]})\n",
    "\n",
    "# Group dataframe and get minimum ord_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1950b",
   "metadata": {},
   "source": [
    "##### 3.2 Realiza un programa que agrupe los datos del dataframe descrito a continuación por el campo 'salesman_id' y una vez hechos estos grupos aplique una suma sobre las columnas 'sale_jan','sale_feb' y 'sale_mar' y la media sobre el resto de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given the following dataframe\n",
    "df = pd.DataFrame({\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001],\n",
    "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6],\n",
    "'sale_feb':[250.5, 170.65, 15.26, 110.5, 598.5, 1400.6, 2760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_mar':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_apr':[150.5, 270.65, 95.26, 210.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_may':[130.5, 270.65, 65.26, 310.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_jun':[150.5, 270.65, 45.26, 110.5, 948.5, 3400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_jul':[950.5, 270.65, 65.26, 210.5, 948.5, 2400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_aug':[150.5, 70.65,  65.26, 110.5, 948.5, 400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_sep':[150.5, 270.65, 65.26, 110.5, 948.5, 200.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_oct':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
    "'sale_nov':[150.5, 270.65, 95.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6], \n",
    "'sale_dec':[150.5, 70.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6]\n",
    "})\n",
    "\n",
    "# Group dataframe and apply aggregated functions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
